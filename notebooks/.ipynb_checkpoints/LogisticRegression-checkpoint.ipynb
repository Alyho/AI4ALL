{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['data', 'labels']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('data/assorted_images/satellite_images.h5', 'r')\n",
    "f.keys()\n",
    "\n",
    "#plopping file with all of our pics into program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[138 145 129]\n",
      "   [127 134 118]\n",
      "   [123 130 114]\n",
      "   ...\n",
      "   [139 149 138]\n",
      "   [151 161 150]\n",
      "   [136 146 135]]\n",
      "\n",
      "  [[ 95 102  86]\n",
      "   [110 117 101]\n",
      "   [139 146 130]\n",
      "   ...\n",
      "   [131 141 130]\n",
      "   [133 143 132]\n",
      "   [120 130 119]]\n",
      "\n",
      "  [[137 144 128]\n",
      "   [137 144 128]\n",
      "   [116 123 107]\n",
      "   ...\n",
      "   [126 136 125]\n",
      "   [128 138 127]\n",
      "   [138 148 137]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 92 105  87]\n",
      "   [146 157 140]\n",
      "   [146 155 138]\n",
      "   ...\n",
      "   [147 156 137]\n",
      "   [158 167 148]\n",
      "   [178 187 168]]\n",
      "\n",
      "  [[138 151 133]\n",
      "   [115 126 109]\n",
      "   [ 99 108  91]\n",
      "   ...\n",
      "   [163 172 153]\n",
      "   [194 203 184]\n",
      "   [163 172 153]]\n",
      "\n",
      "  [[120 133 115]\n",
      "   [117 128 111]\n",
      "   [132 141 124]\n",
      "   ...\n",
      "   [ 90  99  80]\n",
      "   [182 191 172]\n",
      "   [166 175 156]]]\n",
      "\n",
      "\n",
      " [[[ 36  65  47]\n",
      "   [ 71 100  82]\n",
      "   [ 55  79  63]\n",
      "   ...\n",
      "   [ 76  98  77]\n",
      "   [ 84 103  84]\n",
      "   [ 81 100  81]]\n",
      "\n",
      "  [[ 47  74  57]\n",
      "   [ 63  90  73]\n",
      "   [ 67  91  75]\n",
      "   ...\n",
      "   [ 88 110  89]\n",
      "   [ 93 112  93]\n",
      "   [ 82 101  82]]\n",
      "\n",
      "  [[ 58  82  66]\n",
      "   [ 54  78  62]\n",
      "   [ 75  98  82]\n",
      "   ...\n",
      "   [ 94 113  93]\n",
      "   [ 99 116  98]\n",
      "   [ 85 102  84]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115 126  94]\n",
      "   [124 135 105]\n",
      "   [125 135 108]\n",
      "   ...\n",
      "   [ 60  62  49]\n",
      "   [ 68  70  57]\n",
      "   [ 92  94  81]]\n",
      "\n",
      "  [[104 117  87]\n",
      "   [113 128  97]\n",
      "   [115 130 101]\n",
      "   ...\n",
      "   [ 63  65  54]\n",
      "   [ 72  74  61]\n",
      "   [104 106  93]]\n",
      "\n",
      "  [[100 115  84]\n",
      "   [106 121  90]\n",
      "   [ 99 115  88]\n",
      "   ...\n",
      "   [ 99 101  90]\n",
      "   [100 102  89]\n",
      "   [118 120 107]]]\n",
      "\n",
      "\n",
      " [[[109 125 125]\n",
      "   [123 139 139]\n",
      "   [131 147 147]\n",
      "   ...\n",
      "   [ 81 110 114]\n",
      "   [ 96 126 128]\n",
      "   [ 89 120 122]]\n",
      "\n",
      "  [[113 129 129]\n",
      "   [123 139 139]\n",
      "   [125 141 141]\n",
      "   ...\n",
      "   [ 89 117 121]\n",
      "   [ 93 123 125]\n",
      "   [ 94 125 127]]\n",
      "\n",
      "  [[116 132 132]\n",
      "   [123 139 139]\n",
      "   [124 140 140]\n",
      "   ...\n",
      "   [ 93 121 125]\n",
      "   [ 90 118 121]\n",
      "   [ 93 123 125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 82 105 113]\n",
      "   [ 85 110 117]\n",
      "   [ 88 111 119]\n",
      "   ...\n",
      "   [ 83 116 121]\n",
      "   [ 86 121 125]\n",
      "   [ 72 107 111]]\n",
      "\n",
      "  [[ 82 106 116]\n",
      "   [ 84 111 120]\n",
      "   [ 94 118 128]\n",
      "   ...\n",
      "   [ 75 110 114]\n",
      "   [ 78 113 117]\n",
      "   [ 71 106 110]]\n",
      "\n",
      "  [[105 132 141]\n",
      "   [103 130 139]\n",
      "   [106 133 142]\n",
      "   ...\n",
      "   [ 71 106 110]\n",
      "   [ 74 109 113]\n",
      "   [ 70 105 109]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 63  91  92]\n",
      "   [ 90 118 119]\n",
      "   [120 149 147]\n",
      "   ...\n",
      "   [123 155 150]\n",
      "   [101 133 128]\n",
      "   [ 72 104  99]]\n",
      "\n",
      "  [[ 37  65  66]\n",
      "   [ 56  84  85]\n",
      "   [ 89 117 118]\n",
      "   ...\n",
      "   [117 149 144]\n",
      "   [110 142 137]\n",
      "   [ 90 122 117]]\n",
      "\n",
      "  [[ 83 113 115]\n",
      "   [ 77 107 107]\n",
      "   [ 83 111 112]\n",
      "   ...\n",
      "   [ 89 124 118]\n",
      "   [107 142 136]\n",
      "   [103 138 132]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 77 115 116]\n",
      "   [ 75 113 114]\n",
      "   [ 81 119 120]\n",
      "   ...\n",
      "   [ 70 109 114]\n",
      "   [ 86 125 132]\n",
      "   [ 89 128 135]]\n",
      "\n",
      "  [[ 80 119 118]\n",
      "   [ 96 135 134]\n",
      "   [ 95 134 133]\n",
      "   ...\n",
      "   [ 44  83  90]\n",
      "   [ 79 118 125]\n",
      "   [103 142 149]]\n",
      "\n",
      "  [[ 89 128 127]\n",
      "   [121 160 159]\n",
      "   [115 154 153]\n",
      "   ...\n",
      "   [ 44  83  90]\n",
      "   [ 78 117 124]\n",
      "   [ 48  87  94]]]\n",
      "\n",
      "\n",
      " [[[145 145 133]\n",
      "   [125 125 113]\n",
      "   [121 121 109]\n",
      "   ...\n",
      "   [103 112  93]\n",
      "   [106 118  98]\n",
      "   [108 120 100]]\n",
      "\n",
      "  [[156 156 144]\n",
      "   [136 136 124]\n",
      "   [126 126 114]\n",
      "   ...\n",
      "   [115 124 105]\n",
      "   [118 127 108]\n",
      "   [114 126 106]]\n",
      "\n",
      "  [[144 144 132]\n",
      "   [129 129 117]\n",
      "   [122 122 110]\n",
      "   ...\n",
      "   [133 140 122]\n",
      "   [138 145 127]\n",
      "   [133 142 123]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[139 143 129]\n",
      "   [137 141 127]\n",
      "   [126 130 116]\n",
      "   ...\n",
      "   [135 136 120]\n",
      "   [130 131 115]\n",
      "   [122 123 107]]\n",
      "\n",
      "  [[131 135 121]\n",
      "   [133 137 123]\n",
      "   [127 129 116]\n",
      "   ...\n",
      "   [132 130 115]\n",
      "   [133 131 116]\n",
      "   [131 129 114]]\n",
      "\n",
      "  [[128 132 118]\n",
      "   [136 140 126]\n",
      "   [139 141 128]\n",
      "   ...\n",
      "   [130 128 113]\n",
      "   [136 134 119]\n",
      "   [139 137 122]]]\n",
      "\n",
      "\n",
      " [[[158 150 137]\n",
      "   [136 128 115]\n",
      "   [138 130 117]\n",
      "   ...\n",
      "   [140 123 107]\n",
      "   [109  94  75]\n",
      "   [ 86  71  52]]\n",
      "\n",
      "  [[147 139 126]\n",
      "   [107  99  86]\n",
      "   [128 120 107]\n",
      "   ...\n",
      "   [ 83  66  50]\n",
      "   [103  86  68]\n",
      "   [140 123 105]]\n",
      "\n",
      "  [[ 93  85  72]\n",
      "   [ 84  76  63]\n",
      "   [137 129 116]\n",
      "   ...\n",
      "   [ 89  67  53]\n",
      "   [127 106  89]\n",
      "   [148 129 112]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100  86  75]\n",
      "   [ 93  81  69]\n",
      "   [109  97  85]\n",
      "   ...\n",
      "   [123 121 108]\n",
      "   [140 138 125]\n",
      "   [145 143 130]]\n",
      "\n",
      "  [[104  88  75]\n",
      "   [ 88  74  61]\n",
      "   [106  92  81]\n",
      "   ...\n",
      "   [109 105  94]\n",
      "   [ 98  94  83]\n",
      "   [105 101  90]]\n",
      "\n",
      "  [[115  99  86]\n",
      "   [ 89  73  60]\n",
      "   [ 97  83  72]\n",
      "   ...\n",
      "   [ 93  86  76]\n",
      "   [ 61  54  44]\n",
      "   [ 73  66  56]]]]\n",
      "[1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "(641, 224, 224, 3)\n",
      "(641,)\n"
     ]
    }
   ],
   "source": [
    "inds = np.arange(np.array(f['data']).shape[0])\n",
    "np.random.shuffle(inds)\n",
    "dset = np.array(f['data'])[inds]\n",
    "lset = np.array(f['labels'])[inds]\n",
    "#dset = np.random.shuffle(np.array(f['data']))\n",
    "#lset = np.array(f['labels'])\n",
    "\n",
    "print(dset)\n",
    "print(lset)\n",
    "print(dset.shape)\n",
    "print(lset.shape)\n",
    "\n",
    "#taking out the data and labels of our pics and assigining them variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 224, 224, 3)\n",
      "(32, 224, 224, 3)\n",
      "(33, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ratio, val_ratio = 0.9, 0.05\n",
    "\n",
    "X_train = dset[:int(dset.shape[0]*train_ratio), ...] # ... means all the other axes\n",
    "y_train = lset[:int(dset.shape[0]*train_ratio), ...]\n",
    "\n",
    "X_val = dset[int(dset.shape[0]*train_ratio):int(dset.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "y_val = lset[int(dset.shape[0]*train_ratio):int(dset.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "\n",
    "X_test = dset[int(dset.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "y_test = lset[int(dset.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#splitting our data and labels into 3 sets: training, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0709 20:34:30.742079 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # Sequential is one of the main models in Keras, which is basically a sequentially stacked series of layers\n",
    "\n",
    "model = Sequential() # Initialize a Sequential model instance\n",
    "\n",
    "#importing keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 150528)\n",
      "(32, 150528)\n",
      "(33, 150528)\n",
      "Train on 576 samples, validate on 32 samples\n",
      "Epoch 1/20\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 2/20\n",
      "576/576 [==============================] - 0s 631us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 3/20\n",
      "576/576 [==============================] - 0s 715us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 4/20\n",
      "576/576 [==============================] - 0s 667us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 5/20\n",
      "576/576 [==============================] - 0s 630us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 6/20\n",
      "576/576 [==============================] - 0s 631us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 7/20\n",
      "576/576 [==============================] - 0s 615us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 8/20\n",
      "576/576 [==============================] - 0s 617us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 9/20\n",
      "576/576 [==============================] - 0s 635us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 10/20\n",
      "576/576 [==============================] - 0s 619us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 11/20\n",
      "576/576 [==============================] - 0s 634us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 12/20\n",
      "576/576 [==============================] - 0s 615us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 13/20\n",
      "576/576 [==============================] - 0s 622us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 14/20\n",
      "576/576 [==============================] - 0s 636us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 15/20\n",
      "576/576 [==============================] - 0s 606us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 16/20\n",
      "576/576 [==============================] - 0s 640us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 17/20\n",
      "576/576 [==============================] - 0s 722us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 18/20\n",
      "576/576 [==============================] - 0s 636us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 19/20\n",
      "576/576 [==============================] - 0s 655us/step - loss: 0.5151 - val_loss: 0.4877\n",
      "Epoch 20/20\n",
      "576/576 [==============================] - 0s 731us/step - loss: 0.5151 - val_loss: 0.4877\n"
     ]
    }
   ],
   "source": [
    "# # First we'll use fully-connected neural nets\n",
    "from keras.layers import Dense # Dense is Keras's name for fully connected layers\n",
    "\n",
    "# # We can stack layers like lego blocks by simplying using `add()`\n",
    "# # `units` is the number of neurons\n",
    "# # `activation` is the nonlinear function we add for each layer\n",
    "# # We only need to specify `input_dim` which is the input dimension for the layer for the input layer, because for later layers the input is just the output from last layer\n",
    "# # Once again, the number of neurons in hidden layers (e.g., 64 and 16 here) are design choices\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid', input_dim=224*224*3))\n",
    "                \n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr= 0.0001))\n",
    "        \n",
    "# #keras.layers.Dropout(rate = 0.1, noise_shape=.4, seed=.2)\n",
    "\n",
    "# #adding hidden layers of neurons\n",
    "\n",
    "# # Up to this point we're all doing configurations. Now everything is set up so we're letting the model do real things!\n",
    "\n",
    "# # Since now we're using a fully-connected nets, remember we need to flatten the image to a single long vector first\n",
    "X_train_flat = X_train.reshape((-1, 224*224*3)) # -1 means letting NumPy to figure this axis out automatically\n",
    "X_val_flat = X_val.reshape((-1, 224*224*3))\n",
    "X_test_flat = X_test.reshape((-1, 224*224*3))\n",
    "\n",
    "print(X_train_flat.shape)\n",
    "print(X_val_flat.shape)\n",
    "print(X_test_flat.shape)\n",
    "\n",
    "# # Then use fit() to actually train our model\n",
    "# # epochs is basically how many iterations we want for the update process. The model needs some time to reach the optimal state!\n",
    "# # batch_size is how many images we use each time to estimate the gradient. Remember that the more we use the more accurate each update will be, but it will also be slower\n",
    "\n",
    "history = model.fit(X_train_flat, y_train, epochs=20, batch_size=32, validation_data=(X_val_flat, y_val))\n",
    "\n",
    "# #flattens the features and puts the features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 644us/step\n",
      "The test accuracy is: 0.5911531493519292\n",
      "true labels are: [1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "The predicted probabilities are: [[0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.2289818 ]\n",
      " [0.22898178]]\n",
      "The predicted class labels are: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# # Now let's see how our model does\n",
    "acc = model.evaluate(X_test_flat, y_test)\n",
    "print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "# # And make predictions\n",
    "prob = model.predict(X_test_flat) # These are probabilities, and we want to convert them to class labels\n",
    "label = np.array(prob > 0.5, dtype=int)\n",
    "print('true labels are: {}'.format(y_test))\n",
    "print('The predicted probabilities are: {}'.format(prob))\n",
    "print('The predicted class labels are: {}'.format(label))\n",
    "\n",
    "# #output the probabilites given our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
