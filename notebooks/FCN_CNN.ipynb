{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['data', 'labels']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('data/assorted_images/satellite_images.h5', 'r')\n",
    "f.keys()\n",
    "\n",
    "#plopping file with all of our pics into program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 47  63  53]\n",
      "   [ 46  62  52]\n",
      "   [ 48  64  54]\n",
      "   ...\n",
      "   [ 52  68  58]\n",
      "   [ 49  65  55]\n",
      "   [ 46  62  52]]\n",
      "\n",
      "  [[ 49  65  55]\n",
      "   [ 48  64  54]\n",
      "   [ 50  66  56]\n",
      "   ...\n",
      "   [ 49  65  55]\n",
      "   [ 49  65  55]\n",
      "   [ 48  64  54]]\n",
      "\n",
      "  [[ 47  62  55]\n",
      "   [ 47  62  55]\n",
      "   [ 49  64  57]\n",
      "   ...\n",
      "   [ 46  62  52]\n",
      "   [ 49  65  55]\n",
      "   [ 51  67  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 58  56  57]\n",
      "   [ 56  54  55]\n",
      "   [ 56  56  56]\n",
      "   ...\n",
      "   [ 49  61  57]\n",
      "   [ 53  65  61]\n",
      "   [ 46  58  54]]\n",
      "\n",
      "  [[ 57  53  54]\n",
      "   [ 56  54  55]\n",
      "   [ 57  57  57]\n",
      "   ...\n",
      "   [ 49  61  57]\n",
      "   [ 52  64  60]\n",
      "   [ 45  57  53]]\n",
      "\n",
      "  [[ 53  49  50]\n",
      "   [ 56  54  55]\n",
      "   [ 61  59  60]\n",
      "   ...\n",
      "   [ 46  58  54]\n",
      "   [ 48  60  56]\n",
      "   [ 41  53  49]]]\n",
      "\n",
      "\n",
      " [[[110 127 121]\n",
      "   [109 126 120]\n",
      "   [115 127 123]\n",
      "   ...\n",
      "   [135 131 132]\n",
      "   [139 133 135]\n",
      "   [138 132 134]]\n",
      "\n",
      "  [[116 133 127]\n",
      "   [117 132 127]\n",
      "   [122 134 130]\n",
      "   ...\n",
      "   [132 130 131]\n",
      "   [138 134 135]\n",
      "   [138 134 135]]\n",
      "\n",
      "  [[122 137 132]\n",
      "   [123 138 133]\n",
      "   [130 142 138]\n",
      "   ...\n",
      "   [128 130 129]\n",
      "   [133 133 133]\n",
      "   [134 134 134]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[102 132 124]\n",
      "   [ 98 129 121]\n",
      "   [ 92 130 119]\n",
      "   ...\n",
      "   [129 123 125]\n",
      "   [133 124 127]\n",
      "   [136 125 129]]\n",
      "\n",
      "  [[ 99 129 121]\n",
      "   [ 97 128 120]\n",
      "   [ 92 130 119]\n",
      "   ...\n",
      "   [128 122 124]\n",
      "   [132 123 126]\n",
      "   [134 125 128]]\n",
      "\n",
      "  [[ 94 124 116]\n",
      "   [ 98 129 121]\n",
      "   [ 99 137 126]\n",
      "   ...\n",
      "   [127 121 123]\n",
      "   [131 122 125]\n",
      "   [134 125 128]]]\n",
      "\n",
      "\n",
      " [[[105 136 131]\n",
      "   [104 135 130]\n",
      "   [112 143 138]\n",
      "   ...\n",
      "   [127 146 140]\n",
      "   [130 149 143]\n",
      "   [145 164 158]]\n",
      "\n",
      "  [[103 134 129]\n",
      "   [103 134 129]\n",
      "   [113 144 139]\n",
      "   ...\n",
      "   [130 149 143]\n",
      "   [130 149 143]\n",
      "   [143 162 156]]\n",
      "\n",
      "  [[102 133 128]\n",
      "   [102 133 128]\n",
      "   [114 145 140]\n",
      "   ...\n",
      "   [133 152 146]\n",
      "   [133 152 146]\n",
      "   [144 163 157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126 163 146]\n",
      "   [130 167 150]\n",
      "   [135 169 153]\n",
      "   ...\n",
      "   [142 159 149]\n",
      "   [136 153 143]\n",
      "   [132 149 139]]\n",
      "\n",
      "  [[126 165 147]\n",
      "   [128 165 148]\n",
      "   [133 167 151]\n",
      "   ...\n",
      "   [143 160 150]\n",
      "   [136 153 143]\n",
      "   [126 143 133]]\n",
      "\n",
      "  [[127 166 148]\n",
      "   [126 165 147]\n",
      "   [130 164 148]\n",
      "   ...\n",
      "   [145 162 152]\n",
      "   [138 155 145]\n",
      "   [121 138 128]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 92 132 121]\n",
      "   [ 90 130 119]\n",
      "   [ 91 129 118]\n",
      "   ...\n",
      "   [115 134 130]\n",
      "   [116 135 131]\n",
      "   [112 131 127]]\n",
      "\n",
      "  [[ 92 132 121]\n",
      "   [ 91 131 120]\n",
      "   [ 94 132 121]\n",
      "   ...\n",
      "   [109 128 124]\n",
      "   [113 132 128]\n",
      "   [114 133 129]]\n",
      "\n",
      "  [[ 89 131 119]\n",
      "   [ 92 134 122]\n",
      "   [ 95 135 124]\n",
      "   ...\n",
      "   [105 124 120]\n",
      "   [112 131 127]\n",
      "   [118 137 133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[119 140 135]\n",
      "   [101 122 117]\n",
      "   [ 68  91  85]\n",
      "   ...\n",
      "   [121 133 129]\n",
      "   [121 133 129]\n",
      "   [119 131 127]]\n",
      "\n",
      "  [[119 140 135]\n",
      "   [106 127 122]\n",
      "   [ 69  92  86]\n",
      "   ...\n",
      "   [114 129 124]\n",
      "   [114 129 124]\n",
      "   [112 127 122]]\n",
      "\n",
      "  [[108 129 124]\n",
      "   [114 135 130]\n",
      "   [ 83 106 100]\n",
      "   ...\n",
      "   [112 127 122]\n",
      "   [112 127 122]\n",
      "   [110 125 120]]]\n",
      "\n",
      "\n",
      " [[[ 74 113  84]\n",
      "   [ 85 124  95]\n",
      "   [ 86 120  93]\n",
      "   ...\n",
      "   [ 97 120 104]\n",
      "   [ 69  92  76]\n",
      "   [ 32  55  39]]\n",
      "\n",
      "  [[ 82 121  92]\n",
      "   [ 92 131 102]\n",
      "   [ 91 127  99]\n",
      "   ...\n",
      "   [ 94 117 101]\n",
      "   [ 70  93  77]\n",
      "   [ 36  59  43]]\n",
      "\n",
      "  [[ 86 127  97]\n",
      "   [ 96 135 106]\n",
      "   [ 95 131 103]\n",
      "   ...\n",
      "   [105 129 113]\n",
      "   [ 99 122 106]\n",
      "   [ 79 102  86]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 67  94  79]\n",
      "   [ 69  96  81]\n",
      "   [ 62  89  74]\n",
      "   ...\n",
      "   [ 65  94  76]\n",
      "   [ 65  94  76]\n",
      "   [ 62  91  73]]\n",
      "\n",
      "  [[ 65  89  75]\n",
      "   [ 68  92  78]\n",
      "   [ 66  90  76]\n",
      "   ...\n",
      "   [ 73 102  84]\n",
      "   [ 86 115  97]\n",
      "   [ 75 104  86]]\n",
      "\n",
      "  [[ 68  92  78]\n",
      "   [ 67  91  77]\n",
      "   [ 76 100  86]\n",
      "   ...\n",
      "   [ 78 107  89]\n",
      "   [102 131 113]\n",
      "   [ 83 112  94]]]\n",
      "\n",
      "\n",
      " [[[ 81  77  66]\n",
      "   [ 79  75  64]\n",
      "   [ 85  79  67]\n",
      "   ...\n",
      "   [126 112 103]\n",
      "   [123 106  98]\n",
      "   [153 136 128]]\n",
      "\n",
      "  [[ 78  74  63]\n",
      "   [ 78  74  63]\n",
      "   [ 86  80  68]\n",
      "   ...\n",
      "   [123 109 100]\n",
      "   [105  91  82]\n",
      "   [106  92  83]]\n",
      "\n",
      "  [[ 67  64  55]\n",
      "   [ 69  67  55]\n",
      "   [ 78  74  62]\n",
      "   ...\n",
      "   [126 113 104]\n",
      "   [118 105  96]\n",
      "   [101  88  79]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 76  44  33]\n",
      "   [ 85  53  42]\n",
      "   [106  73  64]\n",
      "   ...\n",
      "   [111  96  89]\n",
      "   [113  98  91]\n",
      "   [ 42  27  20]]\n",
      "\n",
      "  [[105  71  61]\n",
      "   [116  84  73]\n",
      "   [137 104  95]\n",
      "   ...\n",
      "   [130 115 108]\n",
      "   [108  93  88]\n",
      "   [ 58  43  38]]\n",
      "\n",
      "  [[128  94  84]\n",
      "   [133  99  89]\n",
      "   [140 107  98]\n",
      "   ...\n",
      "   [ 85  70  63]\n",
      "   [ 96  81  76]\n",
      "   [ 75  60  55]]]]\n",
      "[0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(641, 224, 224, 3)\n",
      "(641,)\n"
     ]
    }
   ],
   "source": [
    "dset = np.array(f['data'])\n",
    "lset = np.array(f['labels'])\n",
    "print(dset)\n",
    "print(lset)\n",
    "print(dset.shape)\n",
    "print(lset.shape)\n",
    "\n",
    "#taking out the data and labels of our pics and assigining them variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 224, 224, 3)\n",
      "(32, 224, 224, 3)\n",
      "(33, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ratio, val_ratio = 0.9, 0.05\n",
    "\n",
    "X_train = dset[:int(dset.shape[0]*train_ratio), ...] # ... means all the other axes\n",
    "y_train = lset[:int(dset.shape[0]*train_ratio), ...]\n",
    "\n",
    "X_val = dset[int(dset.shape[0]*train_ratio):int(dset.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "y_val = lset[int(dset.shape[0]*train_ratio):int(dset.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "\n",
    "X_test = dset[int(dset.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "y_test = lset[int(dset.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#splitting our data and labels into 3 sets: training, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0709 20:44:02.489197 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # Sequential is one of the main models in Keras, which is basically a sequentially stacked series of layers\n",
    "\n",
    "model = Sequential() # Initialize a Sequential model instance\n",
    "\n",
    "#importing keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0709 20:44:02.654783 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0709 20:44:02.662060 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0709 20:44:10.953584 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0709 20:44:11.095118 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0709 20:44:11.114259 140737189909440 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 150528)\n",
      "(32, 150528)\n",
      "(33, 150528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0709 20:44:14.694589 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      "576/576 [==============================] - 15s 27ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 2/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 3/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 4/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 5/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 6/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 7/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 8/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 9/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 10/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "# # First we'll use fully-connected neural nets\n",
    "from keras.layers import Dense # Dense is Keras's name for fully connected layers\n",
    "\n",
    "# # We can stack layers like lego blocks by simplying using `add()`\n",
    "# # `units` is the number of neurons\n",
    "# # `activation` is the nonlinear function we add for each layer\n",
    "# # We only need to specify `input_dim` which is the input dimension for the layer for the input layer, because for later layers the input is just the output from last layer\n",
    "# # Once again, the number of neurons in hidden layers (e.g., 64 and 16 here) are design choices\n",
    "\n",
    "unit_lst = [10, 20, 30, 40, 50, 1]\n",
    "layer_lst = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "model.add(Dense(units=10, activation='relu', input_dim=224*224*3))\n",
    "for layer in layer_lst:\n",
    "    for i in range(len(unit_lst)):\n",
    "         for l in range(layer):\n",
    "            model.add(Dense(units=unit_lst[i], activation='relu'))\n",
    "            \n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "                \n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr= 0.000001))\n",
    "        \n",
    "# #keras.layers.Dropout(rate = 0.1, noise_shape=.4, seed=.2)\n",
    "\n",
    "# #adding hidden layers of neurons\n",
    "\n",
    "# # Up to this point we're all doing configurations. Now everything is set up so we're letting the model do real things!\n",
    "\n",
    "# # Since now we're using a fully-connected nets, remember we need to flatten the image to a single long vector first\n",
    "X_train_flat = X_train.reshape((-1, 224*224*3)) # -1 means letting NumPy to figure this axis out automatically\n",
    "X_val_flat = X_val.reshape((-1, 224*224*3))\n",
    "X_test_flat = X_test.reshape((-1, 224*224*3))\n",
    "\n",
    "print(X_train_flat.shape)\n",
    "print(X_val_flat.shape)\n",
    "print(X_test_flat.shape)\n",
    "\n",
    "# # Then use fit() to actually train our model\n",
    "# # epochs is basically how many iterations we want for the update process. The model needs some time to reach the optimal state!\n",
    "# # batch_size is how many images we use each time to estimate the gradient. Remember that the more we use the more accurate each update will be, but it will also be slower\n",
    "\n",
    "history = model.fit(X_train_flat, y_train, epochs=10, batch_size=32, validation_data=(X_val_flat, y_val))\n",
    "\n",
    "# #flattens the features and puts the features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 960us/step\n",
      "The test accuracy is: 0.6931308580167366\n",
      "The predicted probabilities are: [[0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]\n",
      " [0.49998719]]\n",
      "The predicted class labels are: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# # Now let's see how our model does\n",
    "acc = model.evaluate(X_test_flat, y_test)\n",
    "print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "# # And make predictions\n",
    "prob = model.predict(X_test_flat) # These are probabilities, and we want to convert them to class labels\n",
    "label = np.array(prob > 0.5, dtype=int)\n",
    "\n",
    "print('The predicted probabilities are: {}'.format(prob))\n",
    "print('The predicted class labels are: {}'.format(label))\n",
    "\n",
    "# #output the probabilites given our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0709 20:44:50.383541 140737189909440 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 32 samples\n",
      "Epoch 1/10\n",
      "576/576 [==============================] - 5s 9ms/step - loss: 0.6348 - acc: 0.7847 - val_loss: 0.6198 - val_acc: 0.8125\n",
      "Epoch 2/10\n",
      "576/576 [==============================] - 4s 6ms/step - loss: 0.6320 - acc: 0.7847 - val_loss: 0.6166 - val_acc: 0.8125\n",
      "Epoch 3/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6292 - acc: 0.7847 - val_loss: 0.6135 - val_acc: 0.8125\n",
      "Epoch 4/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6266 - acc: 0.7847 - val_loss: 0.6104 - val_acc: 0.8125\n",
      "Epoch 5/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6240 - acc: 0.7847 - val_loss: 0.6075 - val_acc: 0.8125\n",
      "Epoch 6/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6214 - acc: 0.7847 - val_loss: 0.6046 - val_acc: 0.8125\n",
      "Epoch 7/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6190 - acc: 0.7847 - val_loss: 0.6019 - val_acc: 0.8125\n",
      "Epoch 8/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6166 - acc: 0.7847 - val_loss: 0.5992 - val_acc: 0.8125\n",
      "Epoch 9/10\n",
      "576/576 [==============================] - 4s 7ms/step - loss: 0.6143 - acc: 0.7847 - val_loss: 0.5965 - val_acc: 0.8125\n",
      "Epoch 10/10\n",
      "576/576 [==============================] - 4s 8ms/step - loss: 0.6120 - acc: 0.7847 - val_loss: 0.5940 - val_acc: 0.8125\n",
      "33/33 [==============================] - 0s 3ms/step\n",
      "The test accuracy is: 0.8181818181818182\n",
      "The predicted probabilities are: [[0.40454403]\n",
      " [0.4183248 ]\n",
      " [0.41478074]\n",
      " [0.42662063]\n",
      " [0.4184109 ]\n",
      " [0.40423506]\n",
      " [0.37486094]\n",
      " [0.40958917]\n",
      " [0.40841502]\n",
      " [0.4272729 ]\n",
      " [0.41797662]\n",
      " [0.4121035 ]\n",
      " [0.4195665 ]\n",
      " [0.41722298]\n",
      " [0.41431975]\n",
      " [0.4197664 ]\n",
      " [0.40761253]\n",
      " [0.44438717]\n",
      " [0.41174424]\n",
      " [0.4297592 ]\n",
      " [0.42047903]\n",
      " [0.39401668]\n",
      " [0.4301072 ]\n",
      " [0.42430472]\n",
      " [0.4233326 ]\n",
      " [0.4240332 ]\n",
      " [0.4209111 ]\n",
      " [0.4183566 ]\n",
      " [0.41744363]\n",
      " [0.41698402]\n",
      " [0.4156475 ]\n",
      " [0.385369  ]\n",
      " [0.40585056]]\n",
      "The predicted class labels are: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'train_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8ed14761903c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_acc'"
     ]
    }
   ],
   "source": [
    "# As we can expect, the results are totally random\n",
    "# You can also play with other models, e.g., convnets\n",
    "# So we do the same procedure once more\n",
    "\n",
    "model = Sequential() # Re-initialize the model\n",
    "\n",
    "# Feature extractor\n",
    "# We're using such an architecture: conv -> maxpool -> conv -> maxpool\n",
    "# 'same' padding means we zero-pad the images so that the output will be of the same size as the input\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=3, strides=(2, 2), padding='same'))\n",
    "model.add(keras.layers.Activation('sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # By default the stride is the same as the pooling size\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=2, strides=(1, 1), padding='same'))\n",
    "# model.add(keras.layers.Conv2D(filters = 32, kernel_size = 2, strides = (2, 1), padding = 'same'))\n",
    "model.add(keras.layers.Activation('relu')) # ReLU is another kind of non-linear function\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size = (3, 1)))\n",
    "\n",
    "# Classifier\n",
    "# We're using a 2-layer FC net for classification \n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "# Compilation\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.000001), metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "# Evaluation\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "# train_acc = model.evaluate(X_train, y_train)\n",
    "# print('The training accuracy is: {}'.format(train_acc))\n",
    "print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "# And make predictions\n",
    "prob = model.predict(X_test) # These are probabilities, and we want to convert them to class labels\n",
    "label = np.array(prob > 0.5, dtype=int)\n",
    "\n",
    "print('The predicted probabilities are: {}'.format(prob))\n",
    "print('The predicted class labels are: {}'.format(label))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['train_acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
